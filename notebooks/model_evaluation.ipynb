{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Evaluation of Synthetic Time Series Forecasts\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook evaluates the quality of synthetic time series forecasts generated by Chronos-T5.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import yaml\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add the project root directory to path for importing project modules\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"from src.evaluation import TimeSeriesEvaluator\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load configuration\\n\",\n",
    "    \"with open('../config/config.yaml', 'r') as file:\\n\",\n",
    "    \"    config = yaml.safe_load(file)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display configuration\\n\",\n",
    "    \"print(\\\"Project Configuration:\\\")\\n\",\n",
    "    \"print(yaml.dump(config, sort_keys=False, default_flow_style=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load Evaluation Results\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's load the evaluation results generated by the main process.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Initialize the evaluator\\n\",\n",
    "    \"evaluator = TimeSeriesEvaluator('../config/config.yaml')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluation results file path\\n\",\n",
    "    \"results_file = os.path.join(evaluator.results_path, 'evaluation_results.json')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load evaluation results if available\\n\",\n",
    "    \"if os.path.exists(results_file):\\n\",\n",
    "    \"    with open(results_file, 'r') as f:\\n\",\n",
    "    \"        evaluation_results = json.load(f)\\n\",\n",
    "    \"    print(\\\"Evaluation results loaded successfully.\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(f\\\"Evaluation results file not found at {results_file}\\\")\\n\",\n",
    "    \"    evaluation_results = None\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Display average metrics if available\\n\",\n",
    "    \"if evaluation_results and 'average_metrics' in evaluation_results:\\n\",\n",
    "    \"    avg_metrics = evaluation_results['average_metrics']\\n\",\n",
    "    \"    print(\\\"Average Evaluation Metrics:\\\")\\n\",\n",
    "    \"    for metric, value in avg_metrics.items():\\n\",\n",
    "    \"        print(f\\\"{metric}: {value:.4f}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No average metrics available.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Display individual metrics if available\\n\",\n",
    "    \"if evaluation_results and 'individual_metrics' in evaluation_results:\\n\",\n",
    "    \"    ind_metrics = evaluation_results['individual_metrics']\\n\",\n",
    "    \"    metrics_df = pd.DataFrame.from_dict(ind_metrics, orient='index')\\n\",\n",
    "    \"    print(f\\\"Individual metrics for {len(metrics_df)} time series:\\\")\\n\",\n",
    "    \"    display(metrics_df.head(10))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Summary statistics of metrics\\n\",\n",
    "    \"    print(\\\"\\\\nSummary Statistics:\\\")\\n\",\n",
    "    \"    display(metrics_df.describe())\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No individual metrics available.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Visualize Individual Forecasts\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's visualize some of the individual forecasts generated.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Function to display forecast images\\n\",\n",
    "    \"def display_forecast_images(results_path, max_images=5):\\n\",\n",
    "    \"    \\\"\\\"\\\"Display forecast visualization images\\\"\\\"\\\"\\n\",\n",
    "    \"    forecast_images = [f for f in os.listdir(results_path) if f.startswith('forecast_series_') and f.endswith('.png')]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not forecast_images:\\n\",\n",
    "    \"        print(\\\"No forecast visualization images found.\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Found {len(forecast_images)} forecast visualization images.\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display up to max_images\\n\",\n",
    "    \"    for image_file in forecast_images[:max_images]:\\n\",\n",
    "    \"        image_path = os.path.join(results_path, image_file)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Get series ID from filename\\n\",\n",
    "    \"        series_id = image_file.split('_')[-1].split('.')[0]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Display image\\n\",\n",
    "    \"        plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"        img = plt.imread(image_path)\\n\",\n",
    "    \"        plt.imshow(img)\\n\",\n",
    "    \"        plt.axis('off')\\n\",\n",
    "    \"        plt.title(f\\\"Forecast for Series {series_id}\\\")\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display forecast images\\n\",\n",
    "    \"display_forecast_images(evaluator.results_path)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load and Analyze Synthetic Forecasts\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's load and analyze the synthetic forecasts generated by Chronos-T5.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load synthetic data\\n\",\n",
    "    \"def load_synthetic_data(synthetic_path):\\n\",\n",
    "    \"    \\\"\\\"\\\"Load synthetic forecasts data\\\"\\\"\\\"\\n\",\n",
    "    \"    # Find all forecast series files\\n\",\n",
    "    \"    forecast_files = [f for f in os.listdir(synthetic_path) if f.startswith('forecast_series_') and f.endswith('.csv')]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not forecast_files:\\n\",\n",
    "    \"        print(\\\"No forecast series files found.\\\")\\n\",\n",
    "    \"        return {}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Found {len(forecast_files)} forecast series files.\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load each forecast series\\n\",\n",
    "    \"    forecasts = {}\\n\",\n",
    "    \"    for file in forecast_files:\\n\",\n",
    "    \"        series_id = int(file.split('_')[-1].split('.')[0])\\n\",\n",
    "    \"        path = os.path.join(synthetic_path, file)\\n\",\n",
    "    \"        forecasts[series_id] = pd.read_csv(path)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return forecasts\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load main synthetic data file\\n\",\n",
    "    \"synthetic_files = [f for f in os.listdir(config['data']['synthetic_path']) if f.endswith('.csv') and not f.startswith('forecast_series_')]\\n\",\n",
    "    \"\\n\",\n",
    "    \"if synthetic_files:\\n\",\n",
    "    \"    synthetic_file = synthetic_files[0]  # Use the first synthetic file found\\n\",\n",
    "    \"    synthetic_path = os.path.join(config['data']['synthetic_path'], synthetic_file)\\n\",\n",
    "    \"    synthetic_df = pd.read_csv(synthetic_path)\\n\",\n",
    "    \"    print(f\\\"Loaded main synthetic data file: {synthetic_file}\\\")\\n\",\n",
    "    \"    print(f\\\"Shape: {synthetic_df.shape}\\\")\\n\",\n",
    "    \"    display(synthetic_df.head())\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No main synthetic data file found.\\\")\\n\",\n",
    "    \"    synthetic_df = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load forecast series\\n\",\n",
    "    \"forecasts = load_synthetic_data(config['data']['synthetic_path'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display first forecast\\n\",\n",
    "    \"if forecasts:\\n\",\n",
    "    \"    first_id = list(forecasts.keys())[0]\\n\",\n",
    "    \"    print(f\\\"\\\\nSample forecast for series {first_id}:\\\")\\n\",\n",
    "    \"    display(forecasts[first_id].head())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Analyze Forecast Uncertainty\\n\",\n",
    "    \"\\n\",\n",
    "    \"One of the key advantages of Chronos-T5 is generating probabilistic forecasts. Let's analyze the uncertainty in these forecasts.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def analyze_forecast_uncertainty(forecasts, max_series=3):\\n\",\n",
    "    \"    \\\"\\\"\\\"Analyze uncertainty in probabilistic forecasts\\\"\\\"\\\"\\n\",\n",
    "    \"    if not forecasts:\\n\",\n",
    "    \"        print(\\\"No forecasts available for uncertainty analysis.\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    series_ids = list(forecasts.keys())[:max_series]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for series_id in series_ids:\\n\",\n",
    "    \"        forecast_df = forecasts[series_id]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if 'lower_bound' in forecast_df.columns and 'upper_bound' in forecast_df.columns:\\n\",\n",
    "    \"            # Calculate prediction interval width\\n\",\n",
    "    \"            forecast_df['interval_width'] = forecast_df['upper_bound'] - forecast_df['lower_bound']\\n\",\n",
    "    \"            forecast_df['relative_width'] = forecast_df['interval_width'] / forecast_df['median_forecast']\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Plot median forecast with prediction intervals\\n\",\n",
    "    \"            plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Upper subplot: Forecast with intervals\\n\",\n",
    "    \"            plt.subplot(2, 1, 1)\\n\",\n",
    "    \"            plt.plot(forecast_df['time_idx'], forecast_df['median_forecast'], 'r-', label='Median Forecast')\\n\",\n",
    "    \"            plt.fill_between(\\n\",\n",
    "    \"                forecast_df['time_idx'],\\n\",\n",
    "    \"                forecast_df['lower_bound'],\\n\",\n",
    "    \"                forecast_df['upper_bound'],\\n\",\n",
    "    \"                color='r', alpha=0.3,\\n\",\n",
    "    \"                label='80% Prediction Interval'\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            plt.title(f'Probabilistic Forecast for Series {series_id}')\\n\",\n",
    "    \"            plt.ylabel('Value')\\n\",\n",
    "    \"            plt.grid(True)\\n\",\n",
    "    \"            plt.legend()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Lower subplot: Interval width over time\\n\",\n",
    "    \"            plt.subplot(2, 1, 2)\\n\",\n",
    "    \"            plt.plot(forecast_df['time_idx'], forecast_df['interval_width'], 'b-', label='Interval Width')\\n\",\n",
    "    \"            plt.title('Prediction Interval Width (Uncertainty)')\\n\",\n",
    "    \"            plt.xlabel('Time Step')\\n\",\n",
    "    \"            plt.ylabel('Interval Width')\\n\",\n",
    "    \"            plt.grid(True)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            plt.tight_layout()\\n\",\n",
    "    \"            plt.show()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Display statistics\\n\",\n",
    "    \"            print(f\\\"\\\\nUncertainty Statistics for Series {series_id}:\\\")\\n\",\n",
    "    \"            print(f\\\"Average Interval Width: {forecast_df['interval_width'].mean():.4f}\\\")\\n\",\n",
    "    \"            print(f\\\"Min Interval Width: {forecast_df['interval_width'].min():.4f}\\\")\\n\",\n",
    "    \"            print(f\\\"Max Interval Width: {forecast_df['interval_width'].max():.4f}\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Check if uncertainty grows over time\\n\",\n",
    "    \"            corr = forecast_df['time_idx'].corr(forecast_df['interval_width'])\\n\",\n",
    "    \"            print(f\\\"Correlation between Time and Uncertainty: {corr:.4f}\\\")\\n\",\n",
    "    \"            if corr > 0.5:\\n\",\n",
    "    \"                print(\\\"Uncertainty significantly increases over time.\\\")\\n\",\n",
    "    \"            elif corr < -0.5:\\n\",\n",
    "    \"                print(\\\"Uncertainty significantly decreases over time.\\\")\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                print(\\\"No strong trend in uncertainty over time.\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"Series {series_id} does not have prediction interval data.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Analyze forecast uncertainty\\n\",\n",
    "    \"analyze_forecast_uncertainty(forecasts)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Manual Forecast Generation with Chronos-T5\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's try generating a forecast manually using the Chronos-T5 model.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"from chronos import ChronosPipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"def generate_manual_forecast(sample_data=None, prediction_length=24):\\n\",\n",
    "    \"    \\\"\\\"\\\"Generate a forecast manually using Chronos-T5\\\"\\\"\\\"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # If no sample data provided, create a synthetic time series\\n\",\n",
    "    \"        if sample_data is None:\\n\",\n",
    "    \"            print(\\\"Creating synthetic time series...\\\")\\n\",\n",
    "    \"            # Create a synthetic time series with trend, seasonality, and noise\\n\",\n",
    "    \"            t = np.linspace(0, 4, 200)  # 200 time steps\\n\",\n",
    "    \"            trend = 0.01 * t**2  # Quadratic trend\\n\",\n",
    "    \"            seasonal_1 = 0.5 * np.sin(2 * np.pi * t * 10)  # Fast cycle\\n\",\n",
    "    \"            seasonal_2 = 0.8 * np.sin(2 * np.pi * t)       # Slow cycle\\n\",\n",
    "    \"            noise = 0.1 * np.random.randn(len(t))          # Random noise\\n\",\n",
    "    \"            series = trend + seasonal_1 + seasonal_2 + noise\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Convert to tensor\\n\",\n",
    "    \"            time_series = torch.tensor(series, dtype=torch.float32)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            time_series = torch.tensor(sample_data, dtype=torch.float32)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"Time series shape: {time_series.shape}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Load Chronos-T5 model\\n\",\n",
    "    \"        print(\\\"Loading Chronos-T5-Small model...\\\")\\n\",\n",
    "    \"        pipeline = ChronosPipeline.from_pretrained(\\n\",\n",
    "    \"            \\\"amazon/chronos-t5-small\\\",\\n\",\n",
    "    \"            device_map=\\\"auto\\\",\\n\",\n",
    "    \"            torch_dtype=torch.float32\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Generate forecast\\n\",\n",
    "    \"        print(f\\\"Generating forecast for {prediction_length} future time steps...\\\")\\n\",\n",
    "    \"        forecast = pipeline.predict(\\n\",\n",
    "    \"            time_series,\\n\",\n",
    "    \"            prediction_length,\\n\",\n",
    "    \"            num_samples=20,  # Generate more samples for better uncertainty estimation\\n\",\n",
    "    \"            temperature=0.8\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"Forecast shape: {forecast.shape}\\\")  # Should be [num_samples, prediction_length]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Calculate forecast statistics\\n\",\n",
    "    \"        forecast_np = forecast.numpy()\\n\",\n",
    "    \"        median_forecast = np.median(forecast_np, axis=0)\\n\",\n",
    "    \"        lower_bound = np.percentile(forecast_np, 10, axis=0)\\n\",\n",
    "    \"        upper_bound = np.percentile(forecast_np, 90, axis=0)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Visualize with multiple trajectory samples\\n\",\n",
    "    \"        plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot historical data\\n\",\n",
    "    \"        plt.plot(range(len(time_series)), time_series.numpy(), 'b-', label='Historical Data')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot individual forecast trajectories (a subset)\\n\",\n",
    "    \"        forecast_idx = range(len(time_series), len(time_series) + prediction_length)\\n\",\n",
    "    \"        for i in range(min(5, forecast_np.shape[0])):  # Plot up to 5 trajectories\\n\",\n",
    "    \"            plt.plot(forecast_idx, forecast_np[i], 'gray', alpha=0.3, linewidth=0.5)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        # Plot median forecast and prediction intervals\\n\",\n",
    "    \"        plt.plot(forecast_idx, median_forecast, 'r-', label='Median Forecast')\\n\",\n",
    "    \"        plt.fill_between(forecast_idx, lower_bound, upper_bound, color='r', alpha=0.3, label='80% Prediction Interval')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.title('Manual Time Series Forecast with Chronos-T5')\\n\",\n",
    "    \"        plt.xlabel('Time Step')\\n\",\n",
    "    \"        plt.ylabel('Value')\\n\",\n",
    "    \"        plt.legend()\\n\",\n",
    "    \"        plt.grid(True)\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return forecast_np, median_forecast, lower_bound, upper_bound\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error generating manual forecast: {str(e)}\\\")\\n\",\n",
    "    \"        return None, None, None, None\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate a forecast manually\\n\",\n",
    "    \"forecast_np, median_forecast, lower_bound, upper_bound = generate_manual_forecast(prediction_length=48)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusions and Recommendations\\n\",\n",
    "    \"\\n\",\n",
    "    \"Based on the evaluation of synthetic time series forecasts generated by Chronos-T5, we can draw the following conclusions:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Forecast Accuracy**: The average metrics (RMSE, MAE, MAPE, R²) provide insights into how well the model is forecasting future values. Lower RMSE/MAE/MAPE and higher R² indicate better forecasts.\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Uncertainty Quantification**: Chronos-T5 provides probabilistic forecasts, allowing for uncertainty quantification through prediction intervals. The width of these intervals can help assess the model's confidence in its predictions.\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Forecast Quality**: Visualizing the individual forecasts allows us to qualitatively assess if the model is capturing relevant patterns (trend, seasonality, cycles) in the data.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Recommendations:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Model Selection**: If forecast accuracy is not satisfactory, consider using a larger Chronos model (e.g., chronos-t5-base) for potentially better performance.\\n\",\n",
    "    \"  \\n\",\n",
    "    \"- **Temperature Tuning**: Adjust the temperature parameter (lower for more conservative forecasts, higher for more diverse but potentially less accurate forecasts).\\n\",\n",
    "    \"  \\n\",\n",
    "    \"- **Preprocessing Improvements**: Consider more advanced preprocessing of time series data, such as detrending, seasonal adjustment, or normalization.\\n\",\n",
    "    \"  \\n\",\n",
    "    \"- **Ensemble Approach**: For critical applications, consider an ensemble of different models for improved robustness.\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Data Quality**: The quality of forecasts depends significantly on the quality and quantity of historical data. Ensure that input data is clean and representative.\"\n",
    "   ]\n",
    "  }\n",
    ",\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Check if metrics distribution image exists\\n\",\n",
    "    \"metrics_dist_file = os.path.join(evaluator.results_path, 'metric_distributions.png')\\n\",\n",
    "    \"\\n\",\n",
    "    \"if os.path.exists(metrics_dist_file):\\n\",\n",
    "    \"    plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"    img = plt.imread(metrics_dist_file)\\n\",\n",
    "    \"    plt.imshow(img)\\n\",\n",
    "    \"    plt.axis('off')\\n\",\n",
    "    \"    plt.title(\\\"Distributions of Evaluation Metrics\\\")\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(f\\\"Metrics distribution visualization not found at {metrics_dist_file}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # If we have the metrics dataframe, we can generate the visualization here\\n\",\n",
    "    \"    if 'metrics_df' in locals():\\n\",\n",
    "    \"        plt.figure(figsize=(15, 10))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # RMSE\\n\",\n",
    "    \"        plt.subplot(2, 2, 1)\\n\",\n",
    "    \"        sns.histplot(metrics_df['rmse'].dropna())\\n\",\n",
    "    \"        plt.title('Distribution of RMSE')\\n\",\n",
    "    \"        plt.xlabel('RMSE')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # MAE\\n\",\n",
    "    \"        plt.subplot(2, 2, 2)\\n\",\n",
    "    \"        sns.histplot(metrics_df['mae'].dropna())\\n\",\n",
    "    \"        plt.title('Distribution of MAE')\\n\",\n",
    "    \"        plt.xlabel('MAE')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # MAPE\\n\",\n",
    "    \"        plt.subplot(2, 2, 3)\\n\",\n",
    "    \"        sns.histplot(metrics_df['mape'].dropna())\\n\",\n",
    "    \"        plt.title('Distribution of MAPE (%)')\\n\",\n",
    "    \"        plt.xlabel('MAPE (%)')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # R²\\n\",\n",
    "    \"        plt.subplot(2, 2, 4)\\n\",\n",
    "    \"        sns.histplot(metrics_df['r2'].dropna())\\n\",\n",
    "    \"        plt.title('Distribution of R²')\\n\",\n",
    "    \"        plt.xlabel('R²')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
