{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Exploratory Data Analysis for Time Series\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides exploratory analysis for time series data before generating synthetic forecasts with Chronos-T5.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import yaml\\n\",\n",
    "    \"import h5py\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add the project root directory to path for importing project modules\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"from src.data_preprocessing import DataPreprocessor\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load configuration\\n\",\n",
    "    \"with open('../config/config.yaml', 'r') as file:\\n\",\n",
    "    \"    config = yaml.safe_load(file)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display configuration\\n\",\n",
    "    \"print(\\\"Project Configuration:\\\")\\n\",\n",
    "    \"print(yaml.dump(config, sort_keys=False, default_flow_style=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load and Examine Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Next, we'll load the input data and perform exploratory analysis.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Initialize the data preprocessor\\n\",\n",
    "    \"preprocessor = DataPreprocessor('../config/config.yaml')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Input file (adjust according to your case)\\n\",\n",
    "    \"input_file = \\\"your_data_file.csv\\\"  # or .hdf5, .xlsx, etc.\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    # Load data\\n\",\n",
    "    \"    df = preprocessor.load_data(input_file)\\n\",\n",
    "    \"    print(f\\\"Data loaded with shape: {df.shape}\\\")\\n\",\n",
    "    \"except FileNotFoundError:\\n\",\n",
    "    \"    print(f\\\"File '{input_file}' not found in {preprocessor.raw_path}\\\")\\n\",\n",
    "    \"    print(\\\"Please place your data file in the 'data/raw/' folder\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Display the first few rows\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# General information about the DataFrame\\n\",\n",
    "    \"print(\\\"\\\\nDataFrame Information:\\\")\\n\",\n",
    "    \"df.info()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Descriptive statistics\\n\",\n",
    "    \"df.describe(include='all').T\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## HDF5 File Structure Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"If working with HDF5 files, let's explore the internal structure.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def explore_hdf5_structure(file_path):\\n\",\n",
    "    \"    \\\"\\\"\\\"Explore the structure of an HDF5 file\\\"\\\"\\\"\\n\",\n",
    "    \"    if not file_path.endswith(('.h5', '.hdf5')):\\n\",\n",
    "    \"        print(f\\\"File {file_path} is not an HDF5 file.\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    full_path = os.path.join(preprocessor.raw_path, file_path)\\n\",\n",
    "    \"    if not os.path.exists(full_path):\\n\",\n",
    "    \"        print(f\\\"File {full_path} does not exist.\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Exploring structure of {full_path}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Function to print attributes and metadata of HDF5 objects\\n\",\n",
    "    \"    def print_attrs(name, obj):\\n\",\n",
    "    \"        print(f\\\"\\\\nPath: {name}\\\")\\n\",\n",
    "    \"        print(f\\\"Type: {type(obj).__name__}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if isinstance(obj, h5py.Dataset):\\n\",\n",
    "    \"            print(f\\\"Shape: {obj.shape}\\\")\\n\",\n",
    "    \"            print(f\\\"Data type: {obj.dtype}\\\")\\n\",\n",
    "    \"            if len(obj.shape) == 0 or obj.shape[0] < 5:\\n\",\n",
    "    \"                print(f\\\"Data: {obj[()] if len(obj.shape) == 0 else obj[:][:5]}\\\")\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                print(f\\\"First 5 elements: {obj[:5]}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if obj.attrs:\\n\",\n",
    "    \"            print(\\\"Attributes:\\\")\\n\",\n",
    "    \"            for key, val in obj.attrs.items():\\n\",\n",
    "    \"                print(f\\\"  {key}: {val}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with h5py.File(full_path, 'r') as f:\\n\",\n",
    "    \"        # Print file structure\\n\",\n",
    "    \"        print(\\\"\\\\nHDF5 File Structure:\\\")\\n\",\n",
    "    \"        f.visititems(print_attrs)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Try to explore HDF5 file if it exists\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    explore_hdf5_structure(input_file)\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"Error exploring HDF5 file: {str(e)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Missing Value Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Count missing values by column\\n\",\n",
    "    \"missing_values = df.isnull().sum()\\n\",\n",
    "    \"missing_percentage = (missing_values / len(df)) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_df = pd.DataFrame({\\n\",\n",
    "    \"    'Missing Values': missing_values,\\n\",\n",
    "    \"    'Percentage': missing_percentage\\n\",\n",
    "    \"}).sort_values('Missing Values', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display columns with missing values\\n\",\n",
    "    \"missing_df[missing_df['Missing Values'] > 0]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Visualize missing values\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\\n\",\n",
    "    \"plt.title('Missing Values Heatmap')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Time Series Extraction and Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's extract and analyze potential time series from the dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Identify numeric columns that could be time series\\n\",\n",
    "    \"numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\\n\",\n",
    "    \"print(f\\\"Found {len(numeric_cols)} numeric columns that could contain time series data:\\\")\\n\",\n",
    "    \"print(numeric_cols[:10], '...' if len(numeric_cols) > 10 else '')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Visualize potential time series\\n\",\n",
    "    \"def visualize_time_series(df, columns, max_cols=5, samples=500):\\n\",\n",
    "    \"    \\\"\\\"\\\"Visualize potential time series from selected columns\\\"\\\"\\\"\\n\",\n",
    "    \"    columns = columns[:min(max_cols, len(columns))]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for col in columns:\\n\",\n",
    "    \"        series = df[col].dropna().values\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Sample if series is too long\\n\",\n",
    "    \"        if len(series) > samples:\\n\",\n",
    "    \"            indices = np.linspace(0, len(series)-1, samples).astype(int)\\n\",\n",
    "    \"            series = series[indices]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"        plt.plot(series)\\n\",\n",
    "    \"        plt.title(f'Time Series: {col}')\\n\",\n",
    "    \"        plt.xlabel('Time')\\n\",\n",
    "    \"        plt.ylabel('Value')\\n\",\n",
    "    \"        plt.grid(True)\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Display basic statistics\\n\",\n",
    "    \"        print(f\\\"\\\\nStatistics for {col}:\\\")\\n\",\n",
    "    \"        print(f\\\"Length: {len(df[col].dropna())}\\\")\\n\",\n",
    "    \"        print(f\\\"Min: {df[col].min()}\\\")\\n\",\n",
    "    \"        print(f\\\"Max: {df[col].max()}\\\")\\n\",\n",
    "    \"        print(f\\\"Mean: {df[col].mean()}\\\")\\n\",\n",
    "    \"        print(f\\\"Std Dev: {df[col].std()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize first few numeric columns as potential time series\\n\",\n",
    "    \"visualize_time_series(df, numeric_cols, max_cols=3)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Stationarity and Seasonality Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's check if these time series exhibit stationarity or seasonality.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"from statsmodels.tsa.stattools import adfuller\\n\",\n",
    "    \"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\\n\",\n",
    "    \"\\n\",\n",
    "    \"def analyze_stationarity(series, title):\\n\",\n",
    "    \"    \\\"\\\"\\\"Analyze stationarity of a time series\\\"\\\"\\\"\\n\",\n",
    "    \"    # Augmented Dickey-Fuller test\\n\",\n",
    "    \"    result = adfuller(series.dropna())\\n\",\n",
    "    \"    print(f'\\\\nAugmented Dickey-Fuller Test for {title}:')\\n\",\n",
    "    \"    print(f'ADF Statistic: {result[0]:.4f}')\\n\",\n",
    "    \"    print(f'p-value: {result[1]:.4f}')\\n\",\n",
    "    \"    print('Critical Values:')\\n\",\n",
    "    \"    for key, value in result[4].items():\\n\",\n",
    "    \"        print(f'\\\\t{key}: {value:.4f}')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Series is stationary if p-value is less than significance level (e.g., 0.05)\\n\",\n",
    "    \"    is_stationary = result[1] < 0.05\\n\",\n",
    "    \"    print(f'Series is{\\\"\\\" if is_stationary else \\\" not\\\"} stationary with 95% confidence')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot ACF and PACF\\n\",\n",
    "    \"    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"    plot_acf(series.dropna(), ax=ax1, title=f'Autocorrelation Function for {title}')\\n\",\n",
    "    \"    plot_pacf(series.dropna(), ax=ax2, title=f'Partial Autocorrelation Function for {title}')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return is_stationary\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Analyze stationarity of first few numeric columns\\n\",\n",
    "    \"for col in numeric_cols[:2]:  # Limit to 2 columns for brevity\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        is_stationary = analyze_stationarity(df[col], col)\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error analyzing stationarity for {col}: {str(e)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Prepare Time Series for Chronos-T5\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now, let's prepare the time series for use with Chronos-T5.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Preprocess data\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    processed_df = preprocessor.preprocess_data(df, \\\"preprocessed_from_notebook.csv\\\")\\n\",\n",
    "    \"    print(f\\\"Data preprocessed with shape: {processed_df.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"Data saved to {preprocessor.processed_path}/preprocessed_from_notebook.csv\\\")\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"Error during preprocessing: {str(e)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Extract time series for Chronos-T5\\n\",\n",
    "    \"time_series_data = preprocessor.prepare_for_chronos(processed_df)\\n\",\n",
    "    \"print(f\\\"Extracted {len(time_series_data)} time series for Chronos-T5\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display information about each time series\\n\",\n",
    "    \"for i, series in enumerate(time_series_data[:5]):  # Limit to 5 series for brevity\\n\",\n",
    "    \"    print(f\\\"Series {i}: {len(series)} points, range: [{series.min().item():.2f}, {series.max().item():.2f}]\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Visualize the extracted time series\\n\",\n",
    "    \"for i, series in enumerate(time_series_data[:3]):  # Limit to 3 series for brevity\\n\",\n",
    "    \"    plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"    plt.plot(series.numpy())\\n\",\n",
    "    \"    plt.title(f'Time Series {i} for Chronos-T5')\\n\",\n",
    "    \"    plt.xlabel('Time')\\n\",\n",
    "    \"    plt.ylabel('Value')\\n\",\n",
    "    \"    plt.grid(True)\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Test Chronos-T5 Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's run a quick test with a sample series to verify that the model works.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"from chronos import ChronosPipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"def test_chronos_model(time_series, prediction_length=24):\\n\",\n",
    "    \"    \\\"\\\"\\\"Test Chronos-T5 model on a sample time series\\\"\\\"\\\"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        print(\\\"Loading Chronos-T5-Small model...\\\")\\n\",\n",
    "    \"        pipeline = ChronosPipeline.from_pretrained(\\n\",\n",
    "    \"            \\\"amazon/chronos-t5-small\\\",\\n\",\n",
    "    \"            device_map=\\\"auto\\\",\\n\",\n",
    "    \"            torch_dtype=torch.float32\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"Generating forecast for {prediction_length} future steps...\\\")\\n\",\n",
    "    \"        forecast = pipeline.predict(\\n\",\n",
    "    \"            time_series, \\n\",\n",
    "    \"            prediction_length,\\n\",\n",
    "    \"            num_samples=10,  # Number of trajectories to sample\\n\",\n",
    "    \"            temperature=0.8\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"Forecast generated with shape: {forecast.shape}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Calculate forecast statistics\\n\",\n",
    "    \"        forecast_np = forecast.numpy()\\n\",\n",
    "    \"        median_forecast = np.median(forecast_np, axis=0)\\n\",\n",
    "    \"        lower_bound = np.percentile(forecast_np, 10, axis=0)\\n\",\n",
    "    \"        upper_bound = np.percentile(forecast_np, 90, axis=0)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Visualize forecast\\n\",\n",
    "    \"        plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Historical data\\n\",\n",
    "    \"        historical = time_series.numpy()\\n\",\n",
    "    \"        plt.plot(range(len(historical)), historical, color='blue', label='Historical Data')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Forecast\\n\",\n",
    "    \"        forecast_idx = range(len(historical), len(historical) + prediction_length)\\n\",\n",
    "    \"        plt.plot(forecast_idx, median_forecast, color='red', label='Forecast (median)')\\n\",\n",
    "    \"        plt.fill_between(forecast_idx, lower_bound, upper_bound, color='red', alpha=0.3, label='80% Prediction Interval')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.title('Time Series Forecast with Chronos-T5')\\n\",\n",
    "    \"        plt.grid(True)\\n\",\n",
    "    \"        plt.legend()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return forecast_np\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error testing Chronos model: {str(e)}\\\")\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test with the first time series (if available)\\n\",\n",
    "    \"if time_series_data and len(time_series_data) > 0:\\n\",\n",
    "    \"    sample_series = time_series_data[0]\\n\",\n",
    "    \"    forecast = test_chronos_model(sample_series, prediction_length=24)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No time series available for testing\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusions and Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this notebook, we have:\\n\",\n",
    "    \"1. Loaded and explored the input data\\n\",\n",
    "    \"2. Analyzed potential time series for stationarity and seasonality\\n\",\n",
    "    \"3. Preprocessed the data for use with Chronos-T5\\n\",\n",
    "    \"4. Extracted time series and visualized them\\n\",\n",
    "    \"5. Tested the Chronos-T5 model on a sample time series\\n\",\n",
    "    \"\\n\",\n",
    "    \"Next steps:\\n\",\n",
    "    \"- Run the full synthetic data generation process with `main.py`\\n\",\n",
    "    \"- Evaluate the quality of the synthetic forecasts with the `model_evaluation.ipynb` notebook\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
