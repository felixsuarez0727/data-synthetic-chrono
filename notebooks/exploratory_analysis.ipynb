{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Exploratory Data Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook allows for an exploratory data analysis before generating synthetic data with Chronos-T5.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import yaml\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add the main directory to the path to import project modules\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"from src.data_preprocessing import DataPreprocessor\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load configuration\\n\",\n",
    "    \"with open('../config/config.yaml', 'r') as file:\\n\",\n",
    "    \"    config = yaml.safe_load(file)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display configuration\\n\",\n",
    "    \"print(\\\"Project configuration:\\\")\\n\",\n",
    "    \"print(yaml.dump(config, sort_keys=False, default_flow_style=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load and Examine Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Next, we will load the input data and perform an exploratory analysis.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Initialize the data preprocessor\\n\",\n",
    "    \"preprocessor = DataPreprocessor('../config/config.yaml')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Input file (adjust as needed)\\n\",\n",
    "    \"input_file = \\\"your_data_file.csv\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    # Load data\\n\",\n",
    "    \"    df = preprocessor.load_data(input_file)\\n\",\n",
    "    \"    print(f\\\"Data loaded with shape: {df.shape}\\\")\\n\",\n",
    "    \"except FileNotFoundError:\\n\",\n",
    "    \"    print(f\\\"File '{input_file}' not found in {preprocessor.raw_path}\\\")\\n\",\n",
    "    \"    print(\\\"Please place your CSV file in the 'data/raw/' folder\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Display the first rows\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# General information about the DataFrame\\n\",\n",
    "    \"print(\\\"\\\\nDataFrame Information:\\\")\\n\",\n",
    "    \"df.info()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Descriptive statistics\\n\",\n",
    "    \"df.describe(include='all').T\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Missing Values Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Count missing values per column\\n\",\n",
    "    \"missing_values = df.isnull().sum()\\n\",\n",
    "    \"missing_percentage = (missing_values / len(df)) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_df = pd.DataFrame({\\n\",\n",
    "    \"    'Missing Values': missing_values,\\n\",\n",
    "    \"    'Percentage': missing_percentage\\n\",\n",
    "    \"}).sort_values('Missing Values', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display columns with missing values\\n\",\n",
    "    \"missing_df[missing_df['Missing Values'] > 0]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Visualize missing values\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\\n\",\n",
    "    \"plt.title('Missing Values Heatmap')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Distribution Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Identify numeric columns\\n\",\n",
    "    \"numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize distributions of numeric columns\\n\",\n",
    "    \"for col in numeric_cols[:5]:  # Limit to 5 columns to avoid overloading the notebook\\n\",\n",
    "    \"    plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Histogram\\n\",\n",
    "    \"    plt.subplot(1, 2, 1)\\n\",\n",
    "    \"    sns.histplot(df[col].dropna(), kde=True)\\n\",\n",
    "    \"    plt.title(f'Histogram of {col}')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Boxplot\\n\",\n",
    "    \"    plt.subplot(1, 2, 2)\\n\",\n",
    "    \"    sns.boxplot(x=df[col].dropna())\\n\",\n",
    "    \"    plt.title(f'Boxplot of {col}')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Categorical Variable Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Identify categorical (or text) columns\\n\",\n",
    "    \"categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize distributions of categorical columns\\n\",\n",
    "    \"for col in categorical_cols[:5]:  # Limit to 5 columns\\n\",\n",
    "    \"    if df[col].nunique() < 20:  # Only show if there are fewer than 20 categories\\n\",\n",
    "    \"        plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Count frequencies\\n\",\n",
    "    \"        value_counts = df[col].value_counts()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Create bar chart\\n\",\n",
    "    \"        sns.barplot(x=value_counts.index, y=value_counts.values)\\n\",\n",
    "    \"        plt.title(f'Value Frequency in {col}')\\n\",\n",
    "    \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Also show frequency table\\n\",\n",
    "    \"        print(f\\\"\\\\nValue Distribution in '{col}':\\\")\\n\",\n",
    "    \"        percent = df[col].value_counts(normalize=True) * 100\\n\",\n",
    "    \"        counts = df[col].value_counts()\\n\",\n",
    "    \"        freq_df = pd.DataFrame({'Frequency': counts, 'Percentage': percent})\\n\",\n",
    "    \"        display(freq_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusions and Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this notebook, we have:\\n\",\n",
    "    \"1. Loaded and explored the input data\\n\",\n",
    "    \"2. Analyzed missing values, distributions, and outliers\\n\",\n",
    "    \"3. Preprocessed the data for use with Chronos-T5\\n\",\n",
    "    \"4. Split the data into training and test sets\\n\",\n",
    "    \"5. Prepared texts for synthetic data generation\\n\",\n",
    "    \"\\n\",\n",
    "    \"Next steps:\\n\",\n",
    "    \"- Run the synthetic data generation process with `main.py`\\n\",\n",
    "    \"- Evaluate the quality of the synthetic data using the `model_evaluation.ipynb` notebook\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.8.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
